{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"session4-5.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"text","id":"XoC-ORvciubJ"},"cell_type":"markdown","source":["# Co-enhance session 4, 5: 学習"]},{"metadata":{"id":"XolDvpSsi1SK","colab_type":"text"},"cell_type":"markdown","source":["## 環境設定 (Google drive内のファイルへのアクセス)"]},{"metadata":{"id":"oc4HYf_FtCLw","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hHc_1lNJvshx","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","\n","# チーム番号 (必ず自分のチームにする！)\n","os.environ['TEAM'] = ''\n","print('you are team {}'.format(os.environ['TEAM']))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eO32JU0HOWU0","colab_type":"text"},"cell_type":"markdown","source":["## 学習データをモデルが読み込める状態にする  (データ拡張，ミニバッチ化)"]},{"metadata":{"id":"VWgj3BmrOT-k","colab_type":"code","colab":{}},"cell_type":"code","source":["root_dir = \"./gdrive/Team Drives/coenhance_teams/team{}/content\".format(os.getenv('TEAM'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qxsOVHZEOgoj","colab_type":"code","colab":{}},"cell_type":"code","source":["# 深層学習ライブラリpytorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","\n","# 可視化モジュール\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image\n","\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6G29ZTMm6VN-","colab_type":"code","colab":{}},"cell_type":"code","source":["# ミニバッチ化を行う関数\n","def collater(sample):\n","    images = []\n","    classes = []\n","    for i in sample:\n","        images.append(i[0])\n","        classes.append(i[1])\n","    im = torch.stack(images)\n","    cl = torch.tensor(classes)\n","    return im, cl\n","\n","# データ拡張方法\n","preprocess = transforms.Compose([\n","    # 360度ランダムで画像を回転する\n","    transforms.RandomRotation(180),\n","    # ランダムで上下左右反転する\n","    transforms.RandomHorizontalFlip(0.5),\n","    transforms.RandomVerticalFlip(0.5),\n","    # 明るさやコントラストなどのランダムでの調整\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0),\n","    transforms.ToTensor(),\n","    #transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.2, 0.2, 0.2])\n","])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-g8_0HTqOoui","colab_type":"code","colab":{}},"cell_type":"code","source":["# バッチサイズ\n","BATCH_SIZE = 64\n","\n","# 下の可視化で何枚表示するか，バッチサイズより小さくとる\n","show_size = 10\n","\n","# クラスの一覧\n","food = os.listdir(os.path.join(root_dir, \"data\"))\n","food.sort()\n","print(\"classes: \", food)\n","\n","dataset = ImageFolder(os.path.join(root_dir, \"data\"), transform=preprocess)\n","dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collater, num_workers=8)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vv2Mj7Ke_Vib","colab_type":"code","colab":{}},"cell_type":"code","source":["sample = iter(dataloader).next()\n","# キャンバス(幅，高さ)\n","fig = plt.figure(figsize=(20, 10))\n","\n","for i in range(show_size):\n","    im = sample[0][i]\n","    ax = fig.add_subplot(1, show_size, i+1)\n","    plt.imshow(im.numpy().transpose(1, 2, 0))\n","    plt.grid(False)\n","    plt.axis('off')\n","    cl = food[sample[1][i].item()]\n","    ax.title.set_text(cl)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_VH6NZdJ7evJ","colab_type":"text"},"cell_type":"markdown","source":["## CNNのモデルや学習に必要なものの定義"]},{"metadata":{"id":"uxtVx7PDOr2s","colab_type":"code","colab":{}},"cell_type":"code","source":["# 畳み込みニューラルネットワーク1\n","class CNN(nn.Module):\n","    def __init__(self, image_size, num_classes, C=3):\n","        super(CNN, self).__init__()\n","        self.shallow = nn.Sequential(\n","            nn.Conv2d(C, 2*C, kernel_size=4, padding=1, stride=2),\n","            nn.BatchNorm2d(2*C),\n","            nn.ReLU(),\n","            nn.Conv2d(2*C, 4*C, kernel_size=4, padding=1, stride=2),\n","            nn.BatchNorm2d(4*C),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(4*C, 8*C, kernel_size=4, padding=0, stride=4),\n","            nn.Sigmoid()\n","        )\n","        self.GAP = nn.AvgPool2d(image_size)\n","        self.linear = nn.Linear(8*C, num_classes)\n","        self.softmax = nn.Softmax()\n","    \n","    def forward(self, x):\n","        out = self.shallow(x)\n","        out = self.GAP(out)\n","        out = torch.squeeze(out)\n","        out = self.linear(out)\n","        out = self.softmax(out)\n","        return out\n","    \n","    def get_cam(self, x, idx):\n","        self.eval()\n","        camout = self.shallow(x)\n","        # act_mapはGAP前の特徴マップ, (C x image_size x image_size)\n","        act_map = camout[0]\n","        C, H, W = act_map.size()\n","        # weightsは全結合層における重みの値, (C x num_classes)\n","        weights = self.linear.weight.data\n","        N, _ = weights.size()\n","        # camの計算 (num_classes x image_size x image_size)\n","        cam = torch.mm(weights, act_map.view(C, H*W)).view(N, H, W)\n","        # 特定のクラスの重みのみ取り出す\n","        cam = cam[idx]\n","        maxval = cam.max()\n","        minval = cam.min()\n","        cam = (cam - minval) / (maxval - minval)\n","        cam = cam.cpu().detach().numpy()\n","        return cam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Grl-4H2hy2iK","colab_type":"code","colab":{}},"cell_type":"code","source":["# 残差ブロックの定義\n","class ResidualBlock(nn.Module):\n","    def __init__(self, C):\n","        super(ResidualBlock, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(C, C, kernel_size=3, padding=3, dilation=3),\n","            nn.BatchNorm2d(C),\n","            nn.LeakyReLU()\n","        )\n","        \n","    def forward(self, x):\n","        return x + self.model(x)\n","\n","# 畳み込みニューラルネットワーク2 (残差ブロックあり)  \n","class CNN_res(nn.Module):\n","    def __init__(self, image_size, num_classes, residual_num=5, C=3):\n","        super(CNN_res, self).__init__()\n","        self.shallow = []\n","        for i in range(residual_num):\n","            self.shallow.append(ResidualBlock(C))\n","        self.shallow = nn.Sequential(*self.shallow)\n","        self.GAP = nn.AvgPool2d(image_size)\n","        self.linear = nn.Linear(C, num_classes)\n","        self.softmax = nn.Softmax()\n","    \n","    def forward(self, x):\n","        out = self.shallow(x)\n","        out = self.GAP(out)\n","        out = torch.squeeze(out)\n","        out = self.linear(out)\n","        out = self.softmax(out)\n","        return out\n","    \n","    def get_cam(self, x, idx):\n","        self.eval()\n","        camout = self.shallow(x)\n","        # act_mapはGAP前の特徴マップ, (C x image_size x image_size)\n","        act_map = camout[0]\n","        C, H, W = act_map.size()\n","        # weightsは全結合層における重みの値, (C x num_classes)\n","        weights = self.linear.weight.data\n","        N, _ = weights.size()\n","        # camの計算 (num_classes x image_size x image_size)\n","        cam = torch.mm(weights, act_map.view(C, H*W)).view(N, H, W)\n","        # 特定のクラスの重みのみ取り出す\n","        cam = cam[idx]\n","        maxval = cam.max()\n","        minval = cam.min()\n","        cam = (cam - minval) / (maxval - minval)\n","        cam = cam.cpu().detach().numpy()\n","        return cam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CpTXFvS-HaD8","colab_type":"code","colab":{}},"cell_type":"code","source":["# 学習率\n","LEARNING_RATE = 1e-2\n","# ハイパーパラメータβ\n","BETAS = (0.5, 0.999)\n","\n","# GPU使用可能か判定し，deviceに設定\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"GPU visible: {}\".format(torch.cuda.is_available()))\n","\n","# 使用するニューラルネットワークモデル (上は通常，下は残差ブロックあり)\n","#model = CNN(image_size=75, num_classes=len(food))\n","model = CNN_res(image_size=75, num_classes=len(food))\n","\n","# 最適化手法 (勾配の谷をどう降りていくか)\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=BETAS)\n","\n","# 損失関数 (クロスエントロピー)\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ro12mM4mJavF","colab_type":"code","colab":{}},"cell_type":"code","source":["# データ転送 (ある場合GPU)\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ou07hvcFrZ-Y","colab_type":"code","colab":{}},"cell_type":"code","source":["# 重み初期化の時に用いる標準偏差\n","INITSTD=0.1\n","\n","def init_weights(layer):\n","    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear) or isinstance(layer, nn.ConvTranspose2d):\n","        torch.nn.init.normal_(layer.weight, std=INITSTD)\n","        if layer.bias is not None:\n","            torch.nn.init.zeros_(layer.bias)\n","\n","modeldata = model.apply(init_weights)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j9EdrBo-J4Dw","colab_type":"text"},"cell_type":"markdown","source":["## 学習実行！"]},{"metadata":{"id":"aZWVl_tMJ6qJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# 学習を行うエポック数\n","NUM_EPOCHS = 100\n","\n","# モデルを保存するパス\n","save_path = os.path.join(root_dir, \"models\")\n","\n","print('begin training')\n","loss_list = []\n","for ep in range(NUM_EPOCHS):\n","    \n","    begin = time.time()\n","    correct = 0\n","    full = 0\n","    running_loss = 0\n","    cnt = 0\n","    \n","    for it, sample in enumerate(dataloader):\n","        im_batch = sample[0].to(device)\n","        cl_batch = sample[1].to(device)\n","        \n","        optimizer.zero_grad()\n","        out = model(im_batch)\n","        correct += torch.sum(torch.argmax(out, dim=1) == cl_batch).item()\n","        full += BATCH_SIZE\n","        cnt += 1\n","        loss = criterion(out, cl_batch)\n","        loss.backward()\n","        optimizer.step()\n","        loss_list.append(loss.item())\n","        running_loss += loss.item()\n","        \n","        # 10ステップごとに損失関数の値を表示\n","        if it % 10 == 9:\n","            print('{}th iter done \\t| loss: {}'.format(it+1, loss.item(), flush=True))\n","        \n","        \n","    end = time.time()\n","    # エポックごとに損失関数・クラス識別の正解率を表示\n","    print('-' * 100)\n","    print('epoch {:03d} \\t| loss: {:.05f} \\t| train_acc: {:04d}/{:04d} \\t| {:.05f}s per loop'.format(ep+1, running_loss/cnt, correct, full, (end-begin)/cnt), flush=True)\n","    print('-' * 100)\n","    \n","    # 10エポックごとにモデルを保存\n","    if ep % 10 == 9:\n","        path = os.path.join(save_path, 'ep{}.pth'.format(ep+1))\n","        torch.save(model.state_dict(), path)\n","        print('saved model for epoch {} at {}'.format(ep+1, path))\n","        \n","print('done!')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zoXCQTZzHjGH","colab_type":"text"},"cell_type":"markdown","source":["## 学習結果の可視化 (損失グラフ，テストデータのCAM)"]},{"metadata":{"id":"uG_LrxPLBi1C","colab_type":"code","colab":{}},"cell_type":"code","source":["# 学習損失のイテレーションごとのプロット\n","plt.plot(loss_list)\n","plt.title('training loss')\n","plt.ylabel('cross entropy')\n","plt.xlabel('iterations')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FRuOeNAGOzb_","colab_type":"code","colab":{}},"cell_type":"code","source":["# camを画像に乗せてヒートマップにする関数．画像とcamを入力する\n","def cam_on_image(img, mask):\n","\theatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n","\theatmap = np.float32(heatmap) / 255\n","\tcam = heatmap + np.float32(img)\n","\tcam = cam / np.max(cam)\n","\treturn cam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"esbDoVTyOkhU","colab_type":"code","colab":{}},"cell_type":"code","source":["# キャンバスの設定\n","fig = plt.figure(figsize=(10, 10))\n","# タイトル\n","plt.suptitle('visualization of CAM')\n","\n","# dataloader(学習データのローダー)からサンプルを適当に取ってくる\n","for i in dataloader:\n","    im = i[0].to(device)\n","    out = model(im).detach().cpu()[0]\n","    # 普通に分類させる\n","    cl = np.argmax(out)\n","    # 該当したクラスclに関するCAMを取得する\n","    cam = model.get_cam(im, cl)\n","\n","    # 元画像を表示\n","    ax1 = fig.add_subplot(221)\n","    original = i[0][0].numpy().transpose(1, 2, 0)\n","    plt.imshow(original)\n","    plt.grid(False)\n","    plt.axis('off')\n","    gt = food[i[1][0].item()]\n","    ax1.title.set_text('ground truth: {}'.format(gt))\n","    \n","    # CAMの乗った画像を表示\n","    ax2 = fig.add_subplot(222)\n","    plt.imshow(cam_on_image(original, cam))\n","    plt.grid(False)\n","    plt.axis('off')\n","    p = out[cl].item() * 100\n","    classname = food[cl]\n","    ax2.title.set_text('predicted class: {}, {:.02f}%'.format(classname, p))\n","    break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Enhq-aNmABC8","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"YPvthxvT9aCE","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}